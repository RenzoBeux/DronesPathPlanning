# -*- coding: utf-8 -*-
"""TesisAlmeidaBeux.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Z_xBt40T63q0dKRn44ByDb8RlU1HGiF

## Imports
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras import layers, optimizers
import time
tf.config.run_functions_eagerly(True)

"""## Datastet preparation"""

def parseFile(fileName):
  file = open(fileName, 'r')
  res = []
  for line in file:
    res.append(list(map(lambda x: int(x), line.split())))
  return np.array(res)

def load_real_samples():
  trainX = []
  trainy = []
  for i in range(60,100):
    for j in range(1,30):
      trainX.append(parseFile('output/'+str(i)+'/'+str(j)+'.txt'))
      trainy.append(1)
  trainX = np.array(trainX)
  trainy = np.array(trainy)
  X = trainX.astype('float32')
  X = (X - 4) / 4
  return X

train_images = load_real_samples()
train_images = train_images.reshape(-1, 6, 200, 1)
BUFFER_SIZE = 1131
BATCH_SIZE = 32
train_dataset = tf.data.Dataset.from_tensor_slices(train_images)

"""## Custom Evaluator

### Classes

#### coordObject
"""

class coordObject:
    def __init__(self, x: float, y: float):
        self.x = x
        self.y = y

"""#### Obstacle"""

class Obstacle:

    def __init__(self, dimsInit: coordObject, dimsEnd: coordObject, id: int):
        self.dimsInit = dimsInit
        self.dimsEnd = dimsEnd
        self.id = id

    def toSections(self, gridDimensions: coordObject):
        sections = []
        percentageOfSectionInitX = gridDimensions.x * self.dimsInit.x
        percentageOfSectionEndX = gridDimensions.x * self.dimsEnd.x
        percentageOfSectionInitY = gridDimensions.y * self.dimsInit.y
        percentageOfSectionEndY = gridDimensions.y * self.dimsEnd.y
        sectionInitX = int(percentageOfSectionInitX)
        sectionEndX = int(percentageOfSectionEndX)
        sectionInitY = int(percentageOfSectionInitY)
        sectionEndY = int(percentageOfSectionEndY)
        for i in range(sectionInitX, sectionEndX+1):
            for j in range(sectionInitY, sectionEndY+1):
                sections.append(coordObject(i, j))
        return sections

"""#### POI"""

class POI:
    def __init__(self, coords: coordObject, expectedVisitTime: int, id: int):
        # coords is (x,y) pair of numbers in [0..1]
        self.coords = coords
        if (self.coords.x == 1):
            self.coords.x = 0.99
        if (self.coords.y == 1):
            self.coords.y = 0.99
        self.expectedVisitTime = expectedVisitTime
        self.lastVisit = 0
        self.id = id

    def getSection(self, dim: coordObject) -> coordObject:
        percentageOfSectionX = dim.x * self.coords.x
        percentageOfSectionY = dim.y * self.coords.y
        sectionX = int(percentageOfSectionX)
        sectionY = int(percentageOfSectionY)
        result = coordObject(sectionX, sectionY)
        return result

    def markVisited(self, time):
        self.lastVisit = time

"""### Constants"""

from enum import Enum
DIM = coordObject(8, 3)
BIGDIM = coordObject(32, 12)
ORIGIN = coordObject(0, 0)
UAVAMOUNT = 6
TIMELENGTH = 100
POIS = [coordObject(0.031, 0.909), coordObject(0.56, 0.09),
        coordObject(0.937, 0.09), coordObject(0.937, 0.909)]
POIS_TIMES = [10, 18, 18, 18]
OBSTACLES = [
    Obstacle(coordObject(0.32, 0.45), coordObject(0.7, 0.54), 0),
    Obstacle(coordObject(0.94, 0.4), coordObject(0.95, 0.5), 1),
]


OBS_PUNISH = 0.8

# Time to charge must be aprox 2.5 times the BATTERY_CAPACITY
BATTERY_CAPACITY = 20
TIME_TO_CHARGE = 50

PAUSE_TIME = 0.5


class ACTION(Enum):
    STAY = 0
    RIGHT = 1
    DIAG_DOWN_RIGHT = 2
    DOWN = 3
    DIAG_DOWN_LEFT = 4
    LEFT = 5
    DIAG_UP_LEFT = 6
    UP = 7
    DIAG_UP_RIGHT = 8


colors = ['b', 'g', 'r', 'c', 'm', 'k']
markers = ['o', '^', 'v', '<', '>', 's',
           'p', '*', 'h', 'H', 'D', 'd', 'P', 'X']

metrics = ['Coverage', 'Collision', 'Obstacles', 'POIS', 'Uptime']

"""### Helpers"""

class InvalidRoute(Exception):
    pass


def parseFile(fileName):
    file = open(fileName, 'r')
    res = []
    for line in file:
        res.append(list(map(lambda x: int(x), line.split())))
    return res

# given a list of lists of ints, returns a list of ACTIONS
def parseMoves(listOfLists):
    res = []
    for line in listOfLists:
        res.append(list(map(lambda x: ACTION(x), line)))
    return res

# this will return a matrix of lists of ints where each int is the time a drone passed by that square
def populateArea(actions, areaDims: coordObject):
    # res will have areadims.x * areadims.y elements
    res: list[list[list[int]]] = []
    timeOOB = 0
    # initialize res with 0s
    for i in range(areaDims.x):
        res.append([])
        for j in range(areaDims.y):
            res[i].append([])
    # here we will store current pos for each drone
    currentPos: list[coordObject] = []
    # for each drone we will initialize his current point in 0,0
    for i in range(len(actions)):
        currentPos.append(coordObject(0, 0))
    # we mark the initial point of each drone as visited
    for i in range(len(actions)):
        res[currentPos[i].x][currentPos[i].y].append(0)
    # for each drone
    for i in range(len(actions)):
        # we will iterate through the actions
        for j in range(len(actions[i])):
            chosenMove = actions[i][j]
            if chosenMove == ACTION.RIGHT:
                currentPos[i].x = currentPos[i].x + 1
            elif chosenMove == ACTION.DIAG_DOWN_RIGHT:
                currentPos[i].x = currentPos[i].x + 1
                currentPos[i].y = currentPos[i].y - 1
            elif chosenMove == ACTION.DOWN:
                currentPos[i].y = currentPos[i].y - 1
            elif chosenMove == ACTION.DIAG_DOWN_LEFT:
                currentPos[i].y = currentPos[i].y - 1
                currentPos[i].x = currentPos[i].x - 1
            elif chosenMove == ACTION.LEFT:
                currentPos[i].x = currentPos[i].x - 1
            elif chosenMove == ACTION.DIAG_UP_LEFT:
                currentPos[i].x = currentPos[i].x - 1
                currentPos[i].y = currentPos[i].y + 1
            elif chosenMove == ACTION.UP:
                currentPos[i].y = currentPos[i].y + 1
            elif chosenMove == ACTION.DIAG_UP_RIGHT:
                currentPos[i].y = currentPos[i].y + 1
                currentPos[i].x = currentPos[i].x + 1
            outOfBounds =not (currentPos[i].x in range(areaDims.x) and currentPos[i].y in range(areaDims.y))
            if(outOfBounds):
                timeOOB += 1
            else:
                res[currentPos[i].x][currentPos[i].y].append(j)
    return res, timeOOB

def get_duplicates(array):
    c = Counter(array)
    return {k: v for k, v in c.items() if v > 1}

"""### Quality Evaluation Functions

##### Bound
"""

# This function checks that all drones are flying inside the area
def evaluateDronesInArea(actions, areaDims: coordObject) -> bool:
    try:
        area = populateArea(actions, areaDims)
        return True
    except InvalidRoute:
        return False

"""##### Collission"""

# This function will reward if drones don't share the same square at the same time
def evaluateDronesCollision(actions, areaDims: coordObject) -> float:
    area,_ = populateArea(actions, areaDims)
    numberOfDrones = len(actions)
    numberOfTimes = len(actions[0])
    worstCase = numberOfDrones * numberOfTimes  # all time moves together
    res = 0
    for i in range(areaDims.x):
        for j in range(areaDims.y):
            # find the repeted times in the list
            # we dont want to take into account the base
            if (i == ORIGIN.x and j == ORIGIN.y):
                continue
            duplicates = get_duplicates(area[i][j])
            for k in duplicates:
                res = res + duplicates[k]

    return 1 - (res / worstCase)

"""##### Coverage"""

# This function evaluates the coverage of the area
def evaluateCoverageArea(actions, areaDims: coordObject) -> float:
    area,_ = populateArea(actions, areaDims)
    numberOfSquares = areaDims.x * areaDims.y
    res = numberOfSquares
    for i in range(areaDims.x):
        for j in range(areaDims.y):
            if len(area[i][j]) == 0:
                res = res - 1
    return res / numberOfSquares

"""##### Obstacles"""

def flatten_obstacles(areaDims:coordObject):
    """
    Returns a list of all of the coordinates which are considered occupied by obstacles
    """
    obstaclesBySections:list[list[coordObject]] = list(map(lambda obs:obs.toSections(areaDims),OBSTACLES))
    flat_obs:list[coordObject] = []
    # Suboptimal as all hell
    for sectionList in obstaclesBySections:
        for section in sectionList:
            isAccounted = False
            for alreadyAccounted in flat_obs:
                if(alreadyAccounted.x == section.x and alreadyAccounted.y == section.y):
                    isAccounted = True
                    break
            if(not isAccounted):
                flat_obs.append(section)
    return flat_obs

# This function will reward drones for not flying over obstacles
def evaluateObstacles(actions, areaDims: coordObject) -> float:
    area,_ = populateArea(actions, areaDims)
    numberOfDrones = len(actions)
    numberOfTimes = len(actions[0])
    # Worst case is considered as every drone spending every instant over an obstacle
    worstCase = numberOfDrones * numberOfTimes
    flat_obs = flatten_obstacles(areaDims)

    timeOnObs = 0
    for obs in flat_obs:
        x = obs.x
        y = obs.y
        timeOnObs += len(area[x][y])

    return 1 - timeOnObs / worstCase

"""##### POI Visit"""

def evaluatePOICoverage(actions, areaDims: coordObject) -> float:
    area,_ = populateArea(actions, areaDims)
    timeSpentNeedy = [0 for _ in POIS]
    lastVisit = [0 for _ in POIS]
    time = len(actions[0])
    # list of objects is needed to access aux functions
    pois = [POI(coords, 0, 0) for coords in POIS]

    for t in range(time):
        for i, poi in enumerate(pois):
            coords = poi.getSection(areaDims)
            x = coords.x
            y = coords.y
            if(t in area[x][y]):
                lastVisit[i] = t
            elif(t - lastVisit[i] > POIS_TIMES[i]):
                timeSpentNeedy[i] += 1

    totalTimeSpentNeedy = 0
    for needy in timeSpentNeedy:
        totalTimeSpentNeedy += needy

    maxNeedyTimes = [time-poiTime for poiTime in POIS_TIMES]
    maximumNeediness = 0
    for needy in maxNeedyTimes:
        maximumNeediness += needy

    return 1 - totalTimeSpentNeedy/maximumNeediness

"""##### UAV Uptime"""

# This function will return the best score if at all times there is at least one UAV outside base
def evaluateDroneUpTime(actions, areaDims: coordObject) -> float:
    area,_ = populateArea(actions, areaDims)
    time = len(actions[0])
    dronesUp = 0
    breaked = False
    for t in range(time):
        for i in range(areaDims.x):
            if breaked:
                breaked = False
                break
            for j in range(areaDims.y):
                # we dont want to take into account the base
                if (i == ORIGIN.x and j == ORIGIN.y):
                    continue
                if(t in area[i][j]):
                    dronesUp += 1
                    breaked = True
                    break
    return dronesUp/time

"""### Evaluator"""

from collections import Counter

def evaluate(grid):
    gridDimensions = DIM
    # Lets check all drone routes are valid
    area,timeOOB = populateArea(grid,gridDimensions)
    # Further evaluators must be added to this dictionary
    evaluators = {'Coverage':evaluateCoverageArea,'Collision':evaluateDronesCollision,'Obstacles':evaluateObstacles,'POIS':evaluatePOICoverage, 'Uptime': evaluateDroneUpTime}
    evaluateMetric = lambda eval: eval(grid,gridDimensions)
    results = {metric:evaluateMetric(eval) for metric, eval in evaluators.items()}
    # Out of bound is elevated to 8 so as to exascervate errors in this field
    results['OutOfBound'] = (1 - timeOOB / (len(grid) * len(grid[0]))) ** 3
    accumulator = 0
    for v in results.values():
        accumulator += v
    return accumulator/len(results)

def evaluateGAN(generatedList):
    """
    Returns the average of all of the metrics for a given set of moves
    """
    parsedList = parseMoves(generatedList)
    results = evaluate(parsedList)
    return 1 - results

"""## Model Generation

### Generator
"""

def make_generator_model():
    n_nodes = 128 * 2 * 50
    model = tf.keras.Sequential()

    model.add(layers.Dense(n_nodes, input_shape=(200,)))

    model.add(layers.LeakyReLU(alpha=0.2))

    model.add(layers.Reshape((2, 50, 128)))

    model.add(layers.Conv2DTranspose(128, (6,4), strides=(3,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    
    model.add(layers.Conv2DTranspose(128, (1,4),  strides=(1,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))

    model.add(layers.Conv2D(1, (2,50), activation='tanh', padding='same'))

    return model
generator = make_generator_model()
generator.summary()

"""#### Loss"""

def generator_loss(fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def evaluatorOutputLoss(evaluations,fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return 0.8 * tf.reduce_mean(evaluations) +  0.2 * cross_entropy(tf.ones_like(fake_output), fake_output)

"""#### Optimizer"""

generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)

"""### Discriminator"""

def make_discriminator_model():
    model = tf.keras.Sequential()

    #downsample
    model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=(6,200,1))) #3x100x128
    model.add(layers.LeakyReLU(alpha=0.2))

    #downsample
    model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=(3,100,1))) #2x50x128
    model.add(layers.LeakyReLU(alpha=0.2))
    
    # classifier
    model.add(layers.Flatten())
    model.add(layers.Dropout(0.4))
    model.add(layers.Dense(1, activation='sigmoid'))

    # opt = optimizers.Adam(lr=0.0002, beta_1=0.5)
    # model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

    return model
discriminator = make_discriminator_model()
discriminator.summary()

"""#### Loss"""

def discriminator_loss(real_output, fake_output):
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

"""#### Optimizer"""

discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)

"""## Training"""

EPOCHS = 512
noise_dim = 200
num_examples_to_generate = 3
seed = tf.random.normal([num_examples_to_generate, noise_dim])

"""### Train Step"""

# This annotation causes the function to be "compiled".
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])
    evaluations = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)
      for x,route in enumerate(generated_images):
        evaluation = evaluateGAN((route.numpy().reshape(6,200) * 4 + 4).round())
        evaluations = evaluations.write(x,evaluation)
      evaluations = evaluations.stack()
      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)
      gen_loss = evaluatorOutputLoss(evaluations,fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)
      # print("Gen Loss: ",gen_loss)
      # print("Disc Loss: ",disc_loss)
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

"""### Model Training"""

def generate_and_save_images(model, epoch, test_input):
  predictions = model(test_input, training=False)

  for i in range(predictions.shape[0]):
    with open('Generated'+str(i)+'.txt', 'w') as writefile:
      for line in predictions[i, :, :, 0]:
        writefile.write(' '.join([str(int(x)) for x in (line.numpy() * 4 + 4).round()]) + '\n')

def train(dataset, epochs):
  for epoch in range(epochs):
    batched = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
    start = time.time()

    for image_batch in batched:
      train_step(image_batch)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  generate_and_save_images(generator,
                           epochs,
                           seed)

"""# RUN"""

train(train_dataset, EPOCHS)